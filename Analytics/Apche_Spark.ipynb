{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jGsG5edMyEJK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "66b1023a-0863-46f0-cfd9-7981538f35d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Co\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\u001b[0m\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,118 kB]\n",
            "Fetched 2,351 kB in 2s (1,067 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "45 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=d327b9b8ab794a5626a395e5b3092369c9f6147dfdf1c45270cc5d80896de57b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c5cc37375b0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d7843529447c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, PolynomialExpansion, StandardScaler\n",
        "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.functions import log\n",
        "\n",
        "spark_session = SparkSession.builder.appName('bda').getOrCreate()\n",
        "\n",
        "data = spark_session.read.csv(\"CleanData.csv\", header=True, inferSchema=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "2vh5JCdERFKu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q4QpyymRNss",
        "outputId": "84f065d1-05e1-4cdf-c0c9-940067a09dc6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+---------+---------+-------+----------+-------------+---------------+------------+------------+---------------+-----------+\n",
            "|Year|    Total|     Male|   Female|  Ratio|Median Age|Increase Rate|Life Expectancy|   Inflation|Unemployment|            GDP|  Homicides|\n",
            "+----+---------+---------+---------+-------+----------+-------------+---------------+------------+------------+---------------+-----------+\n",
            "|1960|45954.226|24795.178|21159.049|117.185|    18.429|        2.485|         43.355| 6.947368421|         0.4|  3.749265015E9|3.651251851|\n",
            "|1961|47060.915|25363.721|21697.194|116.899|     18.36|        2.277|          44.18| 1.640419948|         0.4|  4.118647627E9|3.651251851|\n",
            "|1962|48161.841|25930.189|22231.652|116.636|    18.271|        2.347|         45.009|-0.516462234|         0.4|  4.310163797E9|3.651251851|\n",
            "|1963| 49325.05|26526.519| 22798.53|116.352|    18.183|        2.425|         46.318| 1.456488448|         0.4|  4.630827383E9|3.651251851|\n",
            "|1964|50552.592|27153.709|23398.883|116.047|    18.084|         2.49|          47.36| 4.179586881|         0.4|  5.204955901E9|3.651251851|\n",
            "|1965|51841.626|27810.773|24030.852|115.729|    17.973|        2.545|         48.462| 5.568635479|         0.4|  5.929231415E9|3.651251851|\n",
            "|1966|53199.414|  28501.4|24698.014|  115.4|    17.852|        2.625|         49.972| 7.227621598|         0.4|  6.561108778E9|3.651251851|\n",
            "|1967|54629.793|29228.649|25401.143|115.068|    17.705|        2.681|          51.16| 6.811399634|         0.4|   7.46451071E9|3.651251851|\n",
            "|1968|56124.743|29988.206|26136.537|114.737|    17.528|        2.718|         52.281| 0.170627348|         0.4|   8.04199916E9|3.651251851|\n",
            "|1969|57676.805|30776.207|26900.599|114.407|    17.346|        2.737|         53.276| 3.186986796|         0.4|  8.683116338E9|3.651251851|\n",
            "|1970|59290.872|31594.424|27696.448|114.074|    17.199|        2.782|          54.57|  5.34984091|         0.4| 1.002750945E10|3.651251851|\n",
            "|1971|60878.781|32382.253|28496.527|113.636|    17.074|        2.507|          52.15| 4.730691482|         0.4|1.0665896682E10|3.651251851|\n",
            "|1972|62509.565|33192.037|29317.529|113.216|    16.972|        2.776|         55.146| 5.183237645|         0.4|   9.41501636E9|3.651251851|\n",
            "|1973|64285.624|34091.252|30194.373|112.906|    16.902|        2.826|         55.546| 23.07008403|         0.4|   6.38342949E9|3.651251851|\n",
            "|1974|66149.169|35033.843|31115.326|112.594|     16.86|        2.888|         55.607| 26.66303485|         0.4|  8.899191919E9|3.651251851|\n",
            "|1975|68126.999|36033.414|32093.585|112.276|    16.849|        3.003|         56.175| 20.90450946|         0.4|1.1230606061E10|3.651251851|\n",
            "|1976|70230.923|37095.743| 33135.18|111.953|    16.865|        3.079|         56.517| 7.158323731|         0.4|1.3168080808E10|3.651251851|\n",
            "|1977|72451.105|38216.474|34234.632|111.631|    16.899|        3.144|         56.857| 10.13296769|         0.4|1.5126060606E10|3.651251851|\n",
            "|1978| 74789.33|39396.326|35393.003|111.311|    16.943|        3.207|         57.398| 6.138692667|         0.4|1.7811515152E10|3.651251851|\n",
            "|1979|77407.341|40711.907|36695.434|110.945|    17.028|        3.666|         58.084| 8.267046976|         0.4|1.9688383838E10|3.651251851|\n",
            "+----+---------+---------+---------+-------+----------+-------------+---------------+------------+------------+---------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for relevant years\n",
        "data = data.filter(data['Year'] >= 1990)\n"
      ],
      "metadata": {
        "id": "1OP21cIWTKEl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare data for population model\n",
        "data_population = data.select('Year', 'Total')\n",
        "data_population = data_population.withColumnRenamed('Total', 'label')"
      ],
      "metadata": {
        "id": "AvCU_YvITM2v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=['Year'], outputCol='features')\n",
        "data_population = assembler.transform(data_population)\n"
      ],
      "metadata": {
        "id": "oNLCk0KRTPlu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_population.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiiwPy70VLnG",
        "outputId": "2bce4f1e-65e9-433f-8c13-741d2e53079e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+--------+\n",
            "|Year|     label|features|\n",
            "+----+----------+--------+\n",
            "|1990|115414.069|[1990.0]|\n",
            "|1991|119203.569|[1991.0]|\n",
            "|1992|122375.179|[1992.0]|\n",
            "|1993|125546.615|[1993.0]|\n",
            "|1994|129245.139|[1994.0]|\n",
            "|1995|133117.476|[1995.0]|\n",
            "|1996| 137234.81|[1996.0]|\n",
            "|1997|141330.267|[1997.0]|\n",
            "|1998|145476.106|[1998.0]|\n",
            "|1999|149694.462|[1999.0]|\n",
            "|2000|154369.924|[2000.0]|\n",
            "|2001|159217.727|[2001.0]|\n",
            "|2002|163262.807|[2002.0]|\n",
            "|2003| 166876.68|[2003.0]|\n",
            "|2004| 170648.62|[2004.0]|\n",
            "|2005|174372.098|[2005.0]|\n",
            "|2006|178069.984|[2006.0]|\n",
            "|2007|181924.521|[2007.0]|\n",
            "|2008|185931.955|[2008.0]|\n",
            "|2009|190123.222|[2009.0]|\n",
            "+----+----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "train_population, test_population = data_population.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "GFILb2oWTTVH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Linear Regression model for population\n",
        "lr = LinearRegression(featuresCol='features', labelCol='label')\n",
        "population_model = lr.fit(train_population)"
      ],
      "metadata": {
        "id": "n_sIE-uMTWZf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "predictions = population_model.transform(test_population)\n",
        "evaluator = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName='r2')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Population Model Accuracy: \", round(accuracy * 100, 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWh9o0MCTZsj",
        "outputId": "7aad0f7a-5ac2-4e6a-f3fe-9c0e0866c7ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Population Model Accuracy:  99.73 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for Unemployment model\n",
        "data_unemployment = data.withColumn(\"label\", log(data['Unemployment']))\n",
        "data_unemployment = assembler.transform(data_unemployment)"
      ],
      "metadata": {
        "id": "CbEZc3U5VUgl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split data into training and testing sets\n",
        "train_unemployment, test_unemployment = data_unemployment.randomSplit([0.8, 0.2], seed=42)\n"
      ],
      "metadata": {
        "id": "dWEjsopiVgs_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polynomial features for Unemployment\n",
        "train_unemployment = poly_expansion.transform(train_unemployment)\n",
        "test_unemployment = poly_expansion.transform(test_unemployment)"
      ],
      "metadata": {
        "id": "gTuspDgmVjfk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Linear Regression model for Unemployment\n",
        "lr = LinearRegression(featuresCol='polyFeatures', labelCol='label')\n",
        "unemployment_model = lr.fit(train_unemployment)\n"
      ],
      "metadata": {
        "id": "jOWXF4aqVq9G"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model\n",
        "predictions = unemployment_model.transform(test_unemployment)\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Unemployment Model Accuracy: \", round(accuracy * 100, 2), \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LiW0GYDWxZf",
        "outputId": "82f60661-446b-4433-b6e4-276c611260ca"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unemployment Model Accuracy:  85.04 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predictions for a specific year\n",
        "year = 2025\n",
        "features_for_prediction = spark.createDataFrame([(year,)], [\"Year\"])\n",
        "features_for_prediction = assembler.transform(features_for_prediction)\n",
        "\n",
        "# Predict population\n",
        "predicted_population = population_model.transform(features_for_prediction).select('prediction').collect()[0][0]\n",
        "print(f\"Predicted Population in {year}: {int(predicted_population)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfhNZZq2XAb-",
        "outputId": "d20cdd14-25b0-40d2-a249-4486306ad625"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Population in 2025: 248870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Predict unemployment\n",
        "predicted_unemployment = unemployment_model.transform(poly_expansion.transform(features_for_prediction)).select('prediction').collect()[0][0]\n",
        "predicted_unemployment = np.exp(predicted_unemployment)\n",
        "print(f\"Predicted Unemployment in {year}: {int(predicted_unemployment)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hPuVB1xXE7i",
        "outputId": "d732b73a-9df4-4d3e-f4c8-3ae3ff22ba7a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Unemployment in 2025: 21\n"
          ]
        }
      ]
    }
  ]
}